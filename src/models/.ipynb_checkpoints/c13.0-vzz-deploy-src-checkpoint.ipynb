{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b2eb9f",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33937e63",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import inflection\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn import ensemble as en\n",
    "from sklearn import cluster as c\n",
    "from sklearn import mixture as mx\n",
    "from scipy.cluster import hierarchy as hc \n",
    "\n",
    "from sklearn.metrics import calinski_harabasz_score,davies_bouldin_score\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import metrics as m\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "from plotly import express as px\n",
    "\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7a075",
   "metadata": {},
   "source": [
    "## 0.1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448d6367",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\raw\\\\Ecommerce.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2728c1648e1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\Dell\\\\Desktop\\\\ciencia_de_dados\\\\0.Comunidade_DS\\\\PA_05\\\\pa005_insiders_clustering\\\\clustering\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data\\\\raw\\\\Ecommerce.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'unicode_escape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unnamed: 8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\raw\\\\Ecommerce.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data\\\\raw\\\\Ecommerce.csv',encoding= 'unicode_escape')\n",
    "df.drop('Unnamed: 8', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6947f31",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887f584",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f315b8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Invoice Number: identificador único de cada transação.\n",
    "* Stock Code Product: código do item.\n",
    "* Description Product: nome do item\n",
    "* Quantity: A quantidade de cada item comprado por transação.\n",
    "* Invoice Date: O dia em que a transação ocorreu\n",
    "* Unit Price: Preço do produto por unidade\n",
    "* Customer ID: identificador único do cliente\n",
    "* Country: O nome do país que o cliente reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a8ce2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3f90f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1 Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310ad85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "old_cols = df1.columns.tolist()\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "new_cols = list(map(snakecase, old_cols))\n",
    "\n",
    "# Rename columns\n",
    "df1.columns = new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb4c0d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.2 Data Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23039ef9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Number of row: {}'.format(df1.shape[0]))\n",
    "print('Number of columns: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b2da4e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.3 Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73965b97",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d8ac96",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4 Check NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df09be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()[df1.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e5b10",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5 Replace NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a93a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Separate dataframe with NAs\n",
    "df_missing = df1.loc[df1.customer_id.isna()]\n",
    "df_full = df1.loc[~df1.customer_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e6f81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checking if any invoice_no in df_missing is present in df_full so we could add the respective customer_id\n",
    "print(df_full.invoice_no.isin(df_missing.invoice_no.drop_duplicates()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870e308",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check the number of unique invoices\n",
    "df_missing.invoice_no.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f848c2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create customer_ids in a reference dataframe\n",
    "df_invoice = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "df_invoice['customer_id'] = np.arange(19000,19000+len(df_invoice),1)\n",
    "\n",
    "# merge original dataframe with reference dataframe\n",
    "df1 = pd.merge(df1,df_invoice, on='invoice_no',how='left')\n",
    "\n",
    "# coalesce - fill the customer_id column with the column that doen not have NA.\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop extra columns\n",
    "df1.drop(columns=['customer_id_x','customer_id_y'], axis=1,inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50579a7d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.6 Change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ff839",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# invoice date\n",
    "df1['invoice_date'] =  pd.to_datetime(df1['invoice_date'], format = '%d-%b-%y')\n",
    "\n",
    "# customer_id\n",
    "df1['customer_id'] = df1['customer_id'].astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9c1f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a99b5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.7 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2270260",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num = df1.select_dtypes(include=['int64','float64'])\n",
    "cat = df1.select_dtypes(exclude=['int64','float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef1fd8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.1 Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0f8c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Central Tendency - Mean, Median\n",
    "\n",
    "ct1 = pd.DataFrame(num.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(num.apply(np.median)).T\n",
    "\n",
    "# Dispersion - Min, Max, Standard Deviation, Range, Skew, Kurtosis\n",
    "\n",
    "d1 = pd.DataFrame(num.apply(np.std)).T\n",
    "d2 = pd.DataFrame(num.apply(np.min)).T\n",
    "d3 = pd.DataFrame(num.apply(np.max)).T\n",
    "d4 = pd.DataFrame(num.apply(lambda x: x.max() - x.min())).T\n",
    "d5 = pd.DataFrame(num.apply(lambda x: x.skew())).T\n",
    "d6 = pd.DataFrame(num.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "# Concatanate\n",
    "num_df = pd.concat([ct1, ct2, d1,d2,d3,d4,d5,d6]).T.reset_index()\n",
    "num_df.columns =['attributes','mean','median','std','min','max','range','skew','kurtosis']\n",
    "num_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d655223",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.2 Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914bdbd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Invoice Nº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162e76d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Identifying all invoice numbers that represent chargebacks\n",
    "df_chargeback = df1.loc[df1.invoice_no.apply(lambda x: bool(re.search('[^0-9]+',x))),:]\n",
    "\n",
    "print('Total number of chargebacks:',df_chargeback.shape[0])\n",
    "print('Percetage of chargebacks:', round((df_chargeback.shape[0]/df1.shape[0]),3))\n",
    "print('Total number or negative quantity: {}'.format(len(df_chargeback[df_chargeback.quantity<0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aecec3b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Stock Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7cc0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Identifying stock codes that contain only characters\n",
    "\n",
    "df1.loc[df1.stock_code.apply(lambda x: bool(re.search('^[a-zA-Z]+$',x))),'stock_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7d6bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**To Do**: remove stock_code that contain ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY',\n",
    "       'DCGSSGIRL', 'PADS', 'B', 'CRUK']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c4e74",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4afedb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ea825",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550f89e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.country.value_counts(normalize=True).head().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2991264",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top 10 countries with the most purchases\n",
    "df1[['customer_id','country']].drop_duplicates().groupby('country').count().reset_index().sort_values(by='customer_id',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad11737",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 Feature Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4956f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb87776",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.1 Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae130f94",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Unit price - Select product with at least 0.04 unit price \n",
    "df2 = df2.loc[df2['unit_price']>=0.04]\n",
    "\n",
    "# Quantity - Remove customers with zero quantity in total\n",
    "total_quantity = df2[['quantity','customer_id']].groupby('customer_id').sum()\n",
    "customers_zero_quantity = total_quantity[total_quantity.quantity==0].index.to_list()\n",
    "\n",
    "df2 = df2.loc[~df2['customer_id'].isin(customers_zero_quantity)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79787af",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.2 Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e6bbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Stock Code - remove stock_code that contain ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL', 'PADS', 'B', 'CRUK']\n",
    "df2 =df2[~df2['stock_code'].isin(['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY',\n",
    "       'DCGSSGIRL', 'PADS', 'B', 'CRUK'])]\n",
    "\n",
    "# Description - remove description\n",
    "df2.drop('description', axis=1, inplace=True)\n",
    "\n",
    "# Country - Keep only country names: (Remove 'European Community', 'Unspecified')\n",
    "df2 =df2[~df2.country.isin(['European Community', 'Unspecified'])]\n",
    "\n",
    "# Bad users\n",
    "df2 = df2[~df2['customer_id'].isin( [16446] )]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc194c02",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2.3 Separate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa05872",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Quantity - CREATE TWO SEPARATE DATAFRAMES\n",
    "# One for the purchases and another for the returns\n",
    "\n",
    "df_chargeback = df2.loc[df2['quantity']<0,:]\n",
    "df_purchases= df2.loc[df2['quantity']>0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2a724",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3.0 Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d0f26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c751e77",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3.1 Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bef38e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The main ideia here is to reduce the data granularity into rows that represent each one a different customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea71e96",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Data reference\n",
    "df_ref = df2[['customer_id']].drop_duplicates().reset_index()\n",
    "df_ref.drop('index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352964c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.1 Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1d729",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gross Revenue per item purchased\n",
    "df_purchases['gross_revenue'] = df_purchases['quantity'] * df_purchases['unit_price']\n",
    "\n",
    "# Gross Revenue per customer\n",
    "df_monetary = df_purchases[['customer_id','gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref  =pd.merge(df_ref, df_monetary, on='customer_id', how='left')\n",
    "\n",
    "# Check NAs\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58405c02",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.2 Recency (Days since the last purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca615f87",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recency - Last Day purchase\n",
    "df_recency = df_purchases[['customer_id','invoice_date']].groupby('customer_id').max().reset_index()\n",
    "df_recency['recency_days'] = (df2['invoice_date'].max()-df_recency['invoice_date']).dt.days\n",
    "df_recency = df_recency[['customer_id','recency_days']].copy()\n",
    "df_ref = pd.merge(df_ref, df_recency, on='customer_id',how='left')\n",
    "\n",
    "# Check NAs\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a95b9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.5 Product variety (Unique products purchased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd434b2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_var = df_purchases[['customer_id','stock_code']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_var, on='customer_id',how='left')\n",
    "df_ref.rename(columns={'stock_code':'product_variety'}, inplace=True)\n",
    "\n",
    "# Check NAs\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef3d57",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.8 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff82d6",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_return = df_chargeback[['customer_id','quantity']].groupby('customer_id').sum().reset_index()\n",
    "df_return.rename(columns={'quantity':'returns'}, inplace=True) # rename column\n",
    "df_ref = pd.merge(df_ref,df_return, on='customer_id', how='left')\n",
    "df_ref['returns'] = df_ref['returns'] * -1\n",
    "df_ref['returns'].fillna(value=0, inplace=True) # Fill NAs with O (clients with no chargebacks)\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93010750",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 3.1.9 Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23675dcb",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_aux = ( df2[['customer_id', 'invoice_no','invoice_date']].drop_duplicates()\n",
    "                                                             .groupby('customer_id')\n",
    "                                                             .agg( max_ = ('invoice_date','max'),\n",
    "                                                                   min_ = ('invoice_date', 'min'),\n",
    "                                                                   days_ = ('invoice_date', lambda x: ((x.max() - x.min()).days)+1 ),\n",
    "                                                                purchases = ('invoice_no','count') )).reset_index()  \n",
    "# Frequency\n",
    "\n",
    "df_aux['frequency'] = df_aux[['purchases','days_']].apply(lambda x: x['purchases']/x['days_'] if x['days_'] != 0 else 0, axis=1)\n",
    " \n",
    "# Merge\n",
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcd599",
   "metadata": {},
   "source": [
    "# 4.0 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592079a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "df_ref.dropna(inplace=True)\n",
    "\n",
    "df4 = df_ref.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212a514",
   "metadata": {},
   "source": [
    "## 4.1 Data Space Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040fb2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_space = df4.copy()\n",
    "\n",
    "# Cols selected after data variation analysis\n",
    "cols_selected = ['customer_id', 'gross_revenue', 'recency_days', 'product_variety', 'frequency', 'returns']\n",
    "\n",
    "df_space = df_space[cols_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8685321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler definition\n",
    "mms = pp.MinMaxScaler()\n",
    "\n",
    "# Standardization \n",
    "\n",
    "df_space['gross_revenue'] = mms.fit_transform( df_space[['gross_revenue']])\n",
    "df_space['recency_days'] = mms.fit_transform( df_space[['recency_days']])\n",
    "df_space['product_variety'] = mms.fit_transform( df_space[['product_variety']])\n",
    "df_space['returns'] = mms.fit_transform( df_space[['returns']])\n",
    "df_space['frequency'] = mms.fit_transform( df_space[['frequency']])\n",
    "\n",
    "X_space = df_space.copy().drop('customer_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e72d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c87e0c",
   "metadata": {},
   "source": [
    "### 4.2 Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b7f8e",
   "metadata": {},
   "source": [
    "**Note**: the dataframe below shows a unique customer per row, a unique tree per column. The values inside each cell represents the position (leaf number) of the respective customer in that tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X = df4[cols_selected].drop(columns=['customer_id','gross_revenue'],axis=1)\n",
    "y =df4['gross_revenue']\n",
    "\n",
    "# model definition\n",
    "rf = en.RandomForestRegressor( n_estimators=100, random_state=42)\n",
    "\n",
    "# model training\n",
    "rf.fit(X,y)\n",
    "\n",
    "# Turn leafs into dataframe\n",
    "df_leaf = pd.DataFrame(rf.apply(X))# Apply trees in the forest to X, return leaf indices\n",
    "df_leaf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e004235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality\n",
    "reducer = umap.UMAP( random_state=42 )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "# plot Tree-Based Embedding using UMAP\n",
    "sns.scatterplot( x='embedding_x', \n",
    "                 y='embedding_y', \n",
    "                 data=df_tree );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff512dcf",
   "metadata": {},
   "source": [
    "# 5.0 Hyperparameter Fine-Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04388c26",
   "metadata": {},
   "source": [
    "This step servers for testing how many clusters fits the model the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87971d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree base embedding into CSV\n",
    "df_tree.to_csv('src\\\\data\\\\tree_based_embedding.csv')\n",
    "\n",
    "# Convert df_tree into X\n",
    "X = df_tree.copy()\n",
    "\n",
    "# Check X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020c4c4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6.0 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aec49d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.1 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aedff40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Final number of clusteres -> 8 \n",
    "k = 8\n",
    "\n",
    "# Model definition\n",
    "model_train = c.KMeans( init='random', n_clusters=k, n_init=10, max_iter=300, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "model_train.fit(X)\n",
    "\n",
    "# Clustering\n",
    "labels = model_train.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecfaedb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.2 Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95296f95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SS ( Silhouette Score )\n",
    "print( 'SS value: {}'.format( m.silhouette_score( X, labels, metric='euclidean' ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01ffe3",
   "metadata": {},
   "source": [
    "# 7.0 Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f846d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df9 = X.copy()\n",
    "\n",
    "# Adding the clustes \n",
    "df9['cluster'] = labels\n",
    "\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee0955",
   "metadata": {},
   "source": [
    "## 7.2 Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 =df4[cols_selected].copy() \n",
    "\n",
    "# Adding the clustes \n",
    "df9['cluster'] = labels\n",
    "\n",
    "# Change data types\n",
    "df9['recency_days'] = df9['recency_days'].astype(int)\n",
    "df9['product_variety'] = df9['product_variety'].astype(int)\n",
    "df9['returns'] = df9['returns'].astype(int)\n",
    "\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a21aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of customers\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby( 'cluster' ).count().reset_index()\n",
    "df_cluster['perc_customer'] = 100*( df_cluster['customer_id'] / df_cluster['customer_id'].sum() )\n",
    "\n",
    "# Average Gross Revenue\n",
    "df_avg_gross_rev = df9[['gross_revenue','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_gross_rev, how='inner',on='cluster')\n",
    "\n",
    "# Average Recency Days\n",
    "df_avg_rec_days = df9[['recency_days','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_rec_days, how='inner',on='cluster')\n",
    "\n",
    "\n",
    "# Average Product Variety\n",
    "df_avg_pv = df9[['product_variety','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_pv, how='inner',on='cluster')\n",
    "\n",
    "# Average frequency\n",
    "df_freq = df9[['frequency','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_freq, how='inner',on='cluster')\n",
    "\n",
    "# Average Returns\n",
    "df_cg = df9[['returns','cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_cg, how='inner',on='cluster')\n",
    "\n",
    "# Assign cluster Insiders number\n",
    "insiders = df_cluster.sort_values(by='gross_revenue', ascending=False).cluster.to_list()[0]\n",
    "\n",
    "# Clusters sorted by gross revenue\n",
    "df_cluster.sort_values(by='gross_revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28591a18",
   "metadata": {},
   "source": [
    "**Cluster Names Ideas:**\n",
    "* 1 Cluster Insiders\n",
    "* 5 Cluster More Products\n",
    "* 7 Cluster Spend Money \n",
    "* 2 Cluster Even More Products\n",
    "* 4 Cluster Less Days\n",
    "* 3 Cluster Less 1k\n",
    "* 6 Cluster Stop Returners\n",
    "* 0 Cluster More Purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7777a528",
   "metadata": {},
   "source": [
    "# 8.0 Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf37a58",
   "metadata": {},
   "source": [
    "## 8.1 Insert into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Drop Last Table\n",
    "query_drop_table = \"\"\"\n",
    "    DROP TABLE insiders\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('src\\\\data\\\\insiders_db.sqlite')\n",
    "conn.execute(query_drop_table)\n",
    "conn.commit()\n",
    "\n",
    "# Create table\n",
    "\n",
    "query_create_table_insiders = \"\"\"\n",
    "    CREATE TABLE insiders (\n",
    "        customer_id     INTEGER,\n",
    "        gross_revenue   REAL,\n",
    "        recency_days    INTERGER,\n",
    "        product_variety INTERGER,\n",
    "        frequency       REAL,\n",
    "        returns         INTEGER,\n",
    "        cluster         INTEGER\n",
    "    \n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "conn.execute( query_create_table_insiders )\n",
    "conn.commit()\n",
    "\n",
    "# Insert data\n",
    "conn = create_engine( 'sqlite:///insiders_db.sqlite')\n",
    "df9.to_sql('insiders', con=conn, if_exists= 'append', index= False) #Index = False\n",
    "\n",
    "\n",
    "# Select data\n",
    "query = '''\n",
    "    SELECT * FROM insiders\n",
    "\n",
    "'''\n",
    "df_query = pd.read_sql_query(query, con=conn)\n",
    "\n",
    "#conn.commit()\n",
    "#conn.close()\n",
    "\n",
    "# Check database table\n",
    "print(df_query.shape)\n",
    "df_query.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
